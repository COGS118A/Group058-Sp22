{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A- Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Alexander Huynh\n",
    "- Yimin Lu\n",
    "- Jenny Vu\n",
    "- Dong Pham\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "\n",
    "\n",
    "The goal for this project is to come up with and image classification model for road signs to aid computer vision style of self driving or computer vision aided driving. We will be using a data set from Kaggle that will have road signs from Germany with about 180 class labels that will be used as a training set. The trainng set will have about 10K images and testing will have about 50K images. We will implement 4 models and will compare them by using cross validation techniques that was taught in class.  We want our model to classify different road signs and will select the model with the best accuracy on a testing set. Accuracy testing will be done by comparing the meta data file that was given."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Traffic sign classification is an important feature of the self-driving car control pipeline. First the image taken from the camera mounted on the self-driving car requires traffic sign detection, since there may be multiple or no signs within the picture, and state-of-the-art object detection deep neural networks are deployed for this task such as Faster R-CNN, R-FCN, SSD, and YOLO V2.</a>[<sup>[1]</sup>](#arcosnote)\n",
    "\n",
    "After object detection has found and cropped out street signs from the original image from the self-driving car's camera, the cropped street sign images now require traffic sign classification to understand whether or not each street sign seen is a stop sign, a yield sign, etc. Which is very important information the self-driving car needs in order to obey traffic rules and keep its passengers safe.</a>[<sup>[2]</sup>](#kakarlanote) The state-of-the-art networks that process this task are Resnet V1 50, Resnet V1 101, Inception V2, Inception Resnet V2, Mobilenet V1, and Darknet-19.</a>[<sup>[1]</sup>](#arcosnote)\n",
    "\n",
    "The state-of-the art models mostly use Residual Networks (ResNets), which are a type of Convolutional Neural Network (CNN) that has adds \"identity shortcut connections\" in order to overcome the vanishing gradient problem which occurs when a network has too many layers.</a>[<sup>[3]</sup>](#kakarlanote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "Self driving cars are the future of transportation in car centric nations. One of the main problems of self driving cars is dectection and recognition of road signs. There are many shapes and objects that people need to discern when driving and it should not be different for computer vision type of self driving. Computer vision style driving allows self driving cars to know what is around the enviornment. Roadsigns warns the driver the rules of the road and helps keep the road safe for driving. We see lots of things when we are driving and we need to be able to discern the noise from the road signs. It is important for an self driving models to  discern roadsigns so they can follow the rules of the road."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "The dataset we will be using is “Traffic Signs (GTSRB plus 162 custom classes)” created by Daniil Deltsov from Kaggle. \n",
    "\n",
    "https://www.kaggle.com/datasets/daniildeltsov/traffic-signs-gtsrb-plus-162-custom-classes\n",
    "\n",
    "The dataset contains 150k images(observations) separated into 205 classes of traffic signs. This dataset is built on the German Traffic Sign Recognition Benchmark Image Set which originally had 43 classes.\n",
    "The images of each sign are assigned to some folder labeled between 0-204. Each class contains 5-40 original images of the sign and additional generated images. The original images varied in background, lighting, and size of sign. By running 5 different transformations 7 times on each original image, more variety of how these traffic signs are viewed is added to the dataset. There is a test folder consisting of 50k images taken from the training set. \n",
    "The observations are png files of different sizes and must be preprocessed before being able to be fed into the models of interest. The images must be presented in a format understood by the computer through matrices and vectors. \n",
    "\n",
    "Additionally, we may rescale or pad the images(?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "For our solution we decided to use 4 different algorithms to solve our traffic sign classification problem.\n",
    "\n",
    "2 of the algorithms are unsupervised to see how such methods perform against supervised methods:\n",
    "- Spectral clustering\n",
    "- SVM\n",
    "\n",
    "2 of the algorithms are supervised methods:\n",
    "- Convolutional Neural Network (ResNet)\n",
    "- Ensemble of CNNs (Voting)\n",
    "\n",
    "We will train each of these algorithms multiple times, and compare their performance against each other. It is known that old-school unsupervised methods have been largely outperformed by modern supervised techniques, however modern supervised algorithms require much more computational power in order to work. We will see if the forecasted performance increase with supervised algorithms is worth it or not in terms of computational usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "The evaluation metric we will use with spectral clustering and SVM algorithms is classification error. This will just be the percentage of correct classifications on the training and/or testing data.\n",
    "\n",
    "Within the CNN models that we will create, we will use cross-entropy with softmax loss, which is a kind of logarithmic loss that uses the softmax function after the last layer of the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traffic signs are designed communicate traffic laws and regulate the flow vehicles using the roads. This prevents accidents and ensures the safety of many drivers. The dataset of images, itself, doesn't pose any privacy risk, but may fail to train algorithms to correctly identify a sign for every instance. Training data available may not be representative of all environmental conditions signs can appear in. Additionally, the signs on which algorithms are trained on may become outdated resulting in the model failing to identify traffic signs.\n",
    "\n",
    "In application to the real world situations, image classification of traffic signs will most likely be utilized for autonomous vehicles or address some need of understanding traffic. Given the purpose of traffic signs, it has potential put lives in harm's way. \n",
    "\n",
    "In order to address issues of safety and traffic sign changes, the regulating administration of transportation would have to have some tests to ensure the algorithms and vehicles meet an acceptable standard to be publicly used. These checks must occur at set frequencies to ensure everything is up to date. There must be clear communication on changes in signs or traffic laws to companies utilizing traffic sign identification in order for it to be safely used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *Communication frequently through Discord*\n",
    "* *Make sure to meet at meeting times*\n",
    "* *Be on top of issues of problems that may arise during project work*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 4/24 |  1 PM |  Brainstorm topics/questions (all)  | Determine best form of communication; Discuss and decide on final project topic; discuss hypothesis; begin background research | \n",
    "| 4/26  |  10 AM |  Do background research on topic (Pelé) | Discuss ideal dataset(s) and ethics; draft project proposal | \n",
    "| 5/1  | 10 AM  | Edit, finalize, and submit proposal; Search for datasets (Beckenbaur)  | Discuss Wrangling and possible analytical approaches; Assign group members to lead each specific part   |\n",
    "| 5/14  | 6 PM  | Import & Wrangle Data ,do some EDA (Maradonna) | Review/Edit wrangling/EDA; Discuss Analysis Plan   |\n",
    "| 5/23  | 12 PM  | Finalize wrangling/EDA; Begin programming for project (Cruyff) | Discuss/edit project code; Complete project |\n",
    "| 6/1  | 12 PM  | Complete analysis; Draft results/conclusion/discussion (Carlos)| Discuss/edit full project |\n",
    "| 6/8  | Before 11:59 PM  | NA | Turn in Final Project  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"arcosnote\"></a>1.[^](#arcosnote): Evaluation of deep neural networks for traffic sign detection systems. *Neurocomputing 2018*. https://paperswithcode.com/paper/evaluation-of-deep-neural-networks-for<br> \n",
    "<a name=\"kakarlanote\"></a>2.[^](#kakarlanote): Traffic Sign Classification using Residual Networks(ResNet). *Syam Kakarla*. https://towardsdatascience.com/traffic-sign-classification-using-residual-networks-resnet-4b550046ff83<br>\n",
    "<a name=\"pytorchnote\"></a>3.[^](#pytorchnote): How Does PyTorch Support ResNet?. *run.ai*. https://www.run.ai/guides/deep-learning-for-computer-vision/pytorch-resnet#ResNet-Architecture<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
